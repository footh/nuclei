{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2e8aca85f8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAEYCAYAAAAEStC3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2ec67150f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from numpy import ogrid, repeat, newaxis\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "# Generate image that will be used for test upsampling\n",
    "# Number of channels is 3 -- we also treat the number of\n",
    "# samples like the number of classes, because later on\n",
    "# that will be used to upsample predictions from the network\n",
    "imsize = 3\n",
    "x, y = ogrid[:imsize, :imsize]\n",
    "img = repeat((x + y)[..., newaxis], 3, 2) / float(imsize + imsize)\n",
    "io.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsample_kernel.shape: (8, 8)\n",
      "[[ 0.015625  0.046875  0.078125  0.109375  0.109375  0.078125  0.046875\n",
      "   0.015625]\n",
      " [ 0.046875  0.140625  0.234375  0.328125  0.328125  0.234375  0.140625\n",
      "   0.046875]\n",
      " [ 0.078125  0.234375  0.390625  0.546875  0.546875  0.390625  0.234375\n",
      "   0.078125]\n",
      " [ 0.109375  0.328125  0.546875  0.765625  0.765625  0.546875  0.328125\n",
      "   0.109375]\n",
      " [ 0.109375  0.328125  0.546875  0.765625  0.765625  0.546875  0.328125\n",
      "   0.109375]\n",
      " [ 0.078125  0.234375  0.390625  0.546875  0.546875  0.390625  0.234375\n",
      "   0.078125]\n",
      " [ 0.046875  0.140625  0.234375  0.328125  0.328125  0.234375  0.140625\n",
      "   0.046875]\n",
      " [ 0.015625  0.046875  0.078125  0.109375  0.109375  0.078125  0.046875\n",
      "   0.015625]]\n",
      "(8, 8, 6, 6)\n",
      "[[ 0.015625  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.015625  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.015625  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.015625  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.015625  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.015625]]\n",
      "[[ 0.046875  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.046875  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.046875  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.046875  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.046875  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.046875]]\n",
      "[[ 0.046875  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.046875  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.046875  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.046875  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.046875  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.046875]]\n",
      "[[ 0.140625  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.140625  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.140625  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.140625  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.140625  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.140625]]\n",
      "[[ 0.078125  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.078125  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.078125  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.078125  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.078125  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.078125]]\n",
      "[[ 0.109375  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.109375  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.109375  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.109375  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.109375  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.109375]]\n",
      "[[ 0.078125  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.078125  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.078125  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.078125  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.078125  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.078125]]\n",
      "[[ 0.078125  0.        0.        0.        0.        0.      ]\n",
      " [ 0.        0.078125  0.        0.        0.        0.      ]\n",
      " [ 0.        0.        0.078125  0.        0.        0.      ]\n",
      " [ 0.        0.        0.        0.078125  0.        0.      ]\n",
      " [ 0.        0.        0.        0.        0.078125  0.      ]\n",
      " [ 0.        0.        0.        0.        0.        0.078125]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def get_kernel_size(factor):\n",
    "    \"\"\"\n",
    "    Find the kernel size given the desired factor of upsampling.\n",
    "    \"\"\"\n",
    "    return 2 * factor - factor % 2\n",
    "\n",
    "\n",
    "def upsample_filt(size):\n",
    "    \"\"\"\n",
    "    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.\n",
    "    \"\"\"\n",
    "    factor = (size + 1) // 2\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    return (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "\n",
    "def bilinear_upsample_weights(factor, number_of_classes):\n",
    "    \"\"\"\n",
    "    Create weights matrix for transposed convolution with bilinear filter\n",
    "    initialization.\n",
    "    \"\"\"\n",
    "    \n",
    "    filter_size = get_kernel_size(factor)\n",
    "    \n",
    "    weights = np.zeros((filter_size,\n",
    "                        filter_size,\n",
    "                        number_of_classes,\n",
    "                        number_of_classes), dtype=np.float32)\n",
    "    \n",
    "    upsample_kernel = upsample_filt(filter_size)\n",
    "    print(f\"upsample_kernel.shape: {upsample_kernel.shape}\")\n",
    "    print(upsample_kernel)\n",
    "    \n",
    "    for i in range(number_of_classes):\n",
    "        \n",
    "        weights[:, :, i, i] = upsample_kernel\n",
    "    \n",
    "    return weights\n",
    "\n",
    "\n",
    "def upsample_tf(factor, input_img):\n",
    "    \n",
    "    number_of_classes = input_img.shape[2]\n",
    "    print(f\"number_of_classes: {number_of_classes}\")\n",
    "    \n",
    "    new_height = input_img.shape[0] * factor\n",
    "    new_width = input_img.shape[1] * factor\n",
    "    \n",
    "    print(f\"img.shape: {img.shape}\")\n",
    "    expanded_img = np.expand_dims(input_img, axis=0)\n",
    "    print(f\"expanded_img.shape: {expanded_img.shape}\")\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "\n",
    "                upsample_filt_pl = tf.placeholder(tf.float32)\n",
    "                logits_pl = tf.placeholder(tf.float32)\n",
    "\n",
    "                upsample_filter_np = bilinear_upsample_weights(factor,\n",
    "                                        number_of_classes)\n",
    "                \n",
    "                print(f\"upsample_filter_np.shape: {upsample_filter_np.shape}\")\n",
    "                #print(upsample_filter_np)\n",
    "\n",
    "                res = tf.nn.conv2d_transpose(logits_pl, upsample_filt_pl,\n",
    "                        output_shape=[1, new_height, new_width, number_of_classes],\n",
    "                        strides=[1, factor, factor, 1])\n",
    "\n",
    "                final_result = sess.run(res,\n",
    "                                feed_dict={upsample_filt_pl: upsample_filter_np,\n",
    "                                           logits_pl: expanded_img})\n",
    "    \n",
    "    return final_result.squeeze()\n",
    "\n",
    "#upsampled_img_tf = upsample_tf(factor=3, input_img=img)\n",
    "#io.imshow(upsampled_img_tf)\n",
    "\n",
    "#uk = upsample_filt(16)\n",
    "#print(f\"uk.shape: {uk.shape}\")\n",
    "#print(uk)\n",
    "w = bilinear_upsample_weights(4, 6)\n",
    "print(w.shape)\n",
    "print(w[0,0,:,:])\n",
    "print(w[0,1,:,:])\n",
    "print(w[1,0,:,:])\n",
    "print(w[1,1,:,:])\n",
    "\n",
    "print(w[0,2,:,:])\n",
    "print(w[0,3,:,:])\n",
    "\n",
    "print(w[7,2,:,:])\n",
    "print(w[2,7,:,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to me that the bilinear upsample weight matrix expects to have the same input/output channels. As such, it creates a diagonal matrix at each point, where the value in the diagonal is equal for each channel x channel matrix. It is symetrical an assigned like: w[0,n,:,:] = w[n,0,:,:] and that uses nth value in the first row of the kernel x kernel matrix, w[1,n,:,:] = w[n,1,:,:] and that uses the nth value of the second row of the k x k matrix, etc.\n",
    "\n",
    "When having mismatched channels, the diagonal matrix would only get partially filled (if iterating on the smaller of the two channels, and result in an error if iterating on the larger of the two)\n",
    "\n",
    "The takeaway is to not use this when channels are not equal. Could use to first tconv, say a 16x16x512 to 256x256x512, then use a regular conv to get the channels down to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "# Construct some test data\n",
    "x, y = np.ogrid[-np.pi:np.pi:100j, -np.pi:np.pi:100j]\n",
    "r = np.sin(np.exp((np.sin(x)**3 + np.cos(y)**2)))\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(r, 0.8)\n",
    "\n",
    "# Display the image and plot all contours found\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(r, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "for n, contour in enumerate(contours):\n",
    "    #print(f\"len(contour): {len(contour)}\")\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=2)\n",
    "\n",
    "ax.axis('image')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "i = Image.open('../jeff.png')\n",
    "ia = np.asarray(i)\n",
    "\n",
    "c = measure.find_contours(ia, 0.5)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(ia, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "for n, contour in enumerate(c):\n",
    "    #print(f\"len(contour): {len(contour)}\")\n",
    "    ax.plot(contour[:, 1], contour[:, 0], linewidth=1)\n",
    "\n",
    "ax.axis('image')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "\n",
    "blank_imga = np.zeros(ia.shape)\n",
    "blank_img = Image.fromarray(blank_imga)\n",
    "\n",
    "#draw = ImageDraw.Draw(blank_img)\n",
    "\n",
    "#print(len(c[15]))\n",
    "#for n, contour in enumerate(c):\n",
    "#draw.polygon(c[15], fill=128, outline=255)\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.imshow(blank_img, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "for n, contour in enumerate(c):\n",
    "    #print(f\"len(contour): {len(contour)}\")\n",
    "    ax2.plot(contour[:, 1], contour[:, 0], linewidth=1)\n",
    "\n",
    "ax2.axis('image')\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "#plt.show()\n",
    "fig2.savefig('../fig.png', pad_inches=0.0, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "def drawShape(img, coordinates, color):\n",
    "    # In order to draw our line in red\n",
    "    img = skimage.color.gray2rgb(img)\n",
    "\n",
    "    # Make sure the coordinates are expressed as integers\n",
    "    coordinates = coordinates.astype(int)\n",
    "\n",
    "    img[coordinates[:, 0], coordinates[:, 1]] = color\n",
    "\n",
    "    return img\n",
    "\n",
    "blank_imga = np.zeros(ia.shape, dtype=np.uint8)\n",
    "blank_img = Image.fromarray(blank_imga)\n",
    "\n",
    "print(f\"ia shape and dtype: {ia.shape}, {ia.dtype}\")\n",
    "print(f\"blank_imga shape and dtype: {blank_imga.shape}, {blank_imga.dtype}\")\n",
    "\n",
    "iac = blank_imga\n",
    "for contour in c:\n",
    "    iac = drawShape(iac, contour, [255, 0, 0]) \n",
    "\n",
    "iaci = Image.fromarray(iac)\n",
    "iaci.save('../con.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 4.62553048 -1.88524209 -0.86667574]\n",
      "  [-4.58414748  4.80840737 -4.49185142]\n",
      "  [ 4.7016369  -2.97438756  0.65414041]]\n",
      "\n",
      " [[ 3.09954261 -3.57569137  4.63727617]\n",
      "  [ 0.31048111 -1.65980541 -4.73414339]\n",
      "  [ 4.4984516   2.93902933 -1.58781484]]]\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 0. 0.]]\n",
      "\n",
      " [[1. 1. 0.]\n",
      "  [0. 1. 1.]\n",
      "  [1. 1. 0.]]]\n",
      "sigmoid:\n",
      "[[[0.99029662 0.13178792 0.29594648]\n",
      "  [0.01010921 0.99190521 0.01107584]\n",
      "  [0.99100131 0.04859646 0.65794289]]\n",
      "\n",
      " [[0.95687387 0.02723363 0.99040884]\n",
      "  [0.57700269 0.15978812 0.00871338]\n",
      "  [0.98899622 0.94974242 0.16969156]]]\n",
      "loss:\n",
      "[[[4.63528124 0.14131926 0.3509009 ]\n",
      "  [0.01016066 4.8165351  0.01113763]\n",
      "  [0.00903942 0.04981698 1.07277756]]\n",
      "\n",
      " [[0.04408369 3.6033027  4.64691361]\n",
      "  [0.86038946 1.83390659 4.74289496]\n",
      "  [0.01106477 0.05156447 0.18595803]]]\n",
      "mean loss:\n",
      "1.504280391317079\n",
      "mean loss 2:\n",
      "1.5042804479599\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "min = -5.\n",
    "max = 5.\n",
    "\n",
    "logits = np.random.rand(2,3,3) * (max-min) + min\n",
    "print(logits)\n",
    "logits = tf.constant(logits)\n",
    "\n",
    "y = np.random.randint(0,2,(2,3,3)) * 1.\n",
    "print(y)\n",
    "\n",
    "sig = tf.nn.sigmoid(logits)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "mloss = tf.reduce_mean(loss)\n",
    "mloss2 = tf.losses.sigmoid_cross_entropy(y, logits)\n",
    "s, l, m, m2 = sess.run([sig, loss, mloss, mloss2])\n",
    "print(\"sigmoid:\")\n",
    "print(s)\n",
    "print(\"loss:\")\n",
    "print(l)\n",
    "print(\"mean loss:\")\n",
    "print(m)\n",
    "print(\"mean loss 2:\")\n",
    "print(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jfaath/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.06611499 -4.88533314 -4.76440215]\n",
      " [-0.0969466  -2.79080541 -4.33087773]\n",
      " [-1.81126979  4.44489837  4.83295778]]\n",
      "[[1. 1. 0.]\n",
      " [0. 1. 1.]\n",
      " [0. 0. 0.]]\n",
      "[[4. 4. 1.]\n",
      " [1. 4. 4.]\n",
      " [1. 1. 1.]]\n",
      "sigmoid:\n",
      "[[0.98314509 0.00749993 0.00845587]\n",
      " [0.47578231 0.05782306 0.01298516]\n",
      " [0.14048473 0.98839789 0.99209997]]\n",
      "loss:\n",
      "[[0.01699857 4.89286134 0.00849183]\n",
      " [0.64584825 2.8503676  4.34394794]\n",
      " [0.15138669 4.45656831 4.84088918]]\n",
      "weighted loss:\n",
      "[[6.79942623e-02 1.95714454e+01 8.49182733e-03]\n",
      " [6.45848251e-01 1.14014704e+01 1.73757918e+01]\n",
      " [1.51386688e-01 4.45656831e+00 4.84088918e+00]]\n",
      "mean loss:\n",
      "2.4674844118250294\n",
      "weighted mean loss:\n",
      "6.502209561677726\n",
      "mean loss 2 (weighted):\n",
      "6.502209186553955\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "min = -5.\n",
    "max = 5.\n",
    "\n",
    "logits = np.random.rand(3,3) * (max-min) + min\n",
    "print(logits)\n",
    "logits = tf.constant(logits)\n",
    "\n",
    "y = np.random.randint(0,2,(3,3)) * 1.\n",
    "print(y)\n",
    "\n",
    "# Weights test\n",
    "w = np.zeros((3,3))\n",
    "w[y==1] = 4.\n",
    "w[y==0] = 1.\n",
    "print(w)\n",
    "w = tf.constant(w)\n",
    "\n",
    "sig = tf.nn.sigmoid(logits)\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "mloss = tf.reduce_mean(loss)\n",
    "\n",
    "loss_w = tf.multiply(loss, w)\n",
    "mloss_w = tf.reduce_mean(loss_w)\n",
    "\n",
    "mloss2 = tf.losses.sigmoid_cross_entropy(y, logits, weights=w)\n",
    "s, l, lw, m, mw, m2 = sess.run([sig, loss, loss_w, mloss, mloss_w, mloss2])\n",
    "print(\"sigmoid:\")\n",
    "print(s)\n",
    "print(\"loss:\")\n",
    "print(l)\n",
    "print(\"weighted loss:\")\n",
    "print(lw)\n",
    "print(\"mean loss:\")\n",
    "print(m)\n",
    "print(\"weighted mean loss:\")\n",
    "print(mw)\n",
    "print(\"mean loss 2 (weighted):\")\n",
    "print(m2)\n",
    "\n",
    "# TODO: test the weighted loss with batches. ie. If I output (batch_size, 256, 256) does the weight matrix need to\n",
    "# be that size (a la per sample weights) or can it be (1, 256, 256) and broadcast to each sample correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jfaath/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "from tensorflow.contrib import slim\n",
    "from tensorflow.contrib.slim.python.slim.nets import resnet_v1\n",
    "\n",
    "reader = pywrap_tensorflow.NewCheckpointReader('../training-runs/init/resnet_v1_50.ckpt')\n",
    "p = tf.placeholder(tf.float32, [None, 256, 256, 3])\n",
    "\n",
    "with slim.arg_scope(resnet_v1.resnet_arg_scope()):\n",
    "    m = resnet_v1.resnet_v1_50(p, is_training=True, global_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n",
      "resnet_v1_50/conv1/weights\n",
      "resnet_v1_50/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/conv1/BatchNorm/beta\n",
      "resnet_v1_50/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/weights\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/weights\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/weights\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/weights\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/weights\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/weights\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm/moving_variance\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/weights\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_mean\n",
      "resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm/moving_variance\n",
      "resnet_v1_50/conv1/BatchNorm/beta\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "v = slim.get_model_variables()\n",
    "print(len(v))\n",
    "vnames = [x.op.name for x in v]\n",
    "for n in vnames:\n",
    "    print(n)\n",
    "on = v[2].op.name\n",
    "print(on)\n",
    "print(reader.has_tensor(on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'trainableVariables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c2d9ea562620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainableVariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'trainableVariables'"
     ]
    }
   ],
   "source": [
    "print(tf.trainableVariables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "159\n",
      "resnet_v1_50/conv1/weights,False\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'trainable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e48f3aeb3882>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p.op.name},{p.trainable}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'trainable'"
     ]
    }
   ],
   "source": [
    "params = tf.trainable_variables()\n",
    "print(len(params))\n",
    "#for p in params:\n",
    "#    print(p.op.name)\n",
    "    \n",
    "params[0].trainable=False\n",
    "params = tf.trainable_variables()\n",
    "print(len(params))\n",
    "for p in params:\n",
    "    print(f\"{p.op.name},{p.trainable}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
