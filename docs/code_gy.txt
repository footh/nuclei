-------------------------
    for mask in masks[1:]:
        mask_img = Image.open(mask)
        if mask_img.mode is not 'L': raise Exception(f"Mask image is not L mode: {mask}")
        full.paste(mask_img, mask=mask_img)
-------------------------
#     c_tconv1 = tf.keras.layers.Conv2DTranspose(TCONV_OUTPUT_CHANNELS, 
#                                               (TCONV_ROOT*2, TCONV_ROOT*2), 
#                                               strides=(TCONV_ROOT, TCONV_ROOT),
#                                               padding='same',
#                                               activation='relu',
#                                               kernel_initializer=bilinear_interp_init)(net)
#     c_tconv1_output = tf.keras.layers.Conv2D(TCONV_OUTPUT_CHANNELS, (1,1), padding='same', activation='relu')(c_tconv1)
# 
#     s_tconv1 = tf.keras.layers.Conv2DTranspose(TCONV_OUTPUT_CHANNELS, 
#                                               (TCONV_ROOT*2, TCONV_ROOT*2), 
#                                               strides=(TCONV_ROOT, TCONV_ROOT),
#                                               padding='same',
#                                               activation='relu',
#                                               kernel_initializer=bilinear_interp_init)(net)
#     s_tconv1_output = tf.keras.layers.Conv2D(TCONV_OUTPUT_CHANNELS, (1,1), padding='same', activation='relu')(s_tconv1)
# 
# 
#     c_tconv2 = tf.keras.layers.Conv2DTranspose(TCONV_OUTPUT_CHANNELS, 
#                                               (TCONV_ROOT*4, TCONV_ROOT*4), 
#                                               strides=(TCONV_ROOT*2, TCONV_ROOT*2),
#                                               padding='same',
#                                               activation='relu',
#                                               kernel_initializer=bilinear_interp_init)(net)
#     c_tconv2_output = tf.keras.layers.Conv2D(TCONV_OUTPUT_CHANNELS, (1,1), padding='same', activation='relu')(c_tconv2)
# 
#     s_tconv2 = tf.keras.layers.Conv2DTranspose(TCONV_OUTPUT_CHANNELS, 
#                                               (TCONV_ROOT*4, TCONV_ROOT*4), 
#                                               strides=(TCONV_ROOT*2, TCONV_ROOT*2),
#                                               padding='same',
#                                               activation='relu',
#                                               kernel_initializer=bilinear_interp_init)(net)
#     s_tconv2_output = tf.keras.layers.Conv2D(TCONV_OUTPUT_CHANNELS, (1,1), padding='same', activation='relu')(s_tconv2)
# 
# 
#     c_fuse = tf.add_n([c_tconv1_output, c_tconv2_output])
#     s_fuse = tf.add_n([s_tconv1_output, s_tconv2_output])
#     
#     tf.logging.debug(c_fuse)
#     tf.logging.debug(s_fuse)
-------------------------
FEATURE_ROOT = 64

def build_custom(img_input):
    upsample_convs = []
    
    # 0
    net = tf.keras.layers.Conv2D(FEATURE_ROOT, (3,3), padding='same', activation='relu')(img_input)
    
    # 1
    net = tf.keras.layers.Conv2D(FEATURE_ROOT*2, (3,3), padding='same', activation='relu')(net)
    net = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(net)
    
    # 2
    net = tf.keras.layers.Conv2D(FEATURE_ROOT*4, (3,3), padding='same', activation='relu')(net)
    net = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(net)

    # 3
    net = tf.keras.layers.Conv2D(FEATURE_ROOT*8, (3,3), padding='same', activation='relu')(net)
    net = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(net)
    tf.logging.debug(f"net after #3: {net}")
    
    upsample_convs.append(net)
    
    # 4
    net = tf.keras.layers.Conv2D(FEATURE_ROOT*8, (3,3), padding='same', activation='relu')(net)
    net = tf.keras.layers.Dropout(rate=DROPOUT_PROB)(net)
    net = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(net)
    tf.logging.debug(f"net after #4: {net}")

    upsample_convs.append(net)

    # 5
    net = tf.keras.layers.Conv2D(FEATURE_ROOT*16, (3,3), padding='same', activation='relu')(net)
    net = tf.keras.layers.Dropout(rate=DROPOUT_PROB)(net)
    net = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same')(net)
    tf.logging.debug(f"net after #5: {net}")

    upsample_convs.append(net)

    return upsample_convs
-------------------------
- This works the same as the current TF version
def bilinear_interp_init(shape, dtype=None, partition_info=None):
    """
        Keras customer initializer for bilinear upsampling
        From: https://github.com/MarvinTeichmann/tensorflow-fcn/blob/master/fcn16_vgg.py#L245
    """
    width = shape[0]
    height = shape[1]
    f = math.ceil(width / 2.0)
    c = (2 * f - 1 - f % 2) / (2.0 * f)
    bilinear = np.zeros((width, height), dtype=dtype.as_numpy_dtype())
    for x in range(width):
        for y in range(height):
            value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))
            bilinear[x,y] = value
    
    tf.logging.debug(bilinear.shape)        
    weights = np.zeros(shape, dtype=dtype.as_numpy_dtype())
    for i in range(shape[2]):
        weights[:,:,i,i] = bilinear
        
    tf.logging.debug(weights.shape)
    return weights
    #return tf.convert_to_tensor(weights, dtype=dtype, name='bilinear_interp_init')
    #return tf.constant(weights, shape=shape, dtype=dtype, name='bilinear_interp_init')
-------------------------
def temp_write(step, x, ys, yc):
    from PIL import Image
    for i in range(len(x)):
        tf.logging.info(f"x[i].shape: {x[i].shape}")
        xi = Image.fromarray(np.asarray(x[i], dtype=np.uint8))
        xi.save(f"./tmp/{step}-x-{i}.png")
        
        ysi = Image.fromarray(ys[i])
        ysi.save(f"./tmp/{step}-ys-{i}.gif")
        yci = Image.fromarray(yc[i])
        yci.save(f"./tmp/{step}-yc-{i}.gif")
-------------------------
    loss_seg = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_seg, logits=logits_seg, name='loss_seg')
    loss_con = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels_con, logits=logits_con, name='loss_con')
    mean_loss_seg = tf.reduce_mean(loss_seg, name='mean_loss_seg')
    mean_loss_con = tf.reduce_mean(loss_con, name='mean_loss_con')
    total_loss = tf.add(mean_loss_seg, mean_loss_con, name='total_loss')
-------------------------
    flist = raw_file_list('test')
    flist = {os.path.basename(f) for f in flist}
    
    class_df = pd.read_csv(os.path.join('raw-data', file))
    new_class_df = pd.DataFrame(columns=['filename', 'foreground', 'background', 'set'])
    for i, row in enumerate(class_df.itertuples()):
        s = 'test' if row.filename in flist else 'train'
        new_row = [row.filename, row.foreground, row.background, s]
        new_class_df.loc[i] = new_row
    
    new_class_df.to_csv('./raw-data/classes2.csv')

loc = '/home/jfaath/Downloads/files'
class_df = pd.read_csv(os.path.join('..', 'classes.csv'))
new_class_df = pd.DataFrame(columns=['filename', 'foreground', 'background', 'rows', 'cols', 'set'])

for i, row in enumerate(class_df.itertuples()):
    name, ext = os.path.splitext(os.path.basename(row.filename))
    imga = np.asarray(Image.open(os.path.join(loc, name, 'images', row.filename)))
    new_row = [row.filename, row.foreground, row.background, imga.shape[0], imga.shape[1], row.set]
    new_class_df.loc[i] = new_row

new_class_df.to_csv('classes2.csv')
-------------------------
CONTOUR_DILATION = {
        20: 2,
        30: 2,
        40: 3,
        60: 4,
        80: 5,
        100: 6,
        150: 7,
        1000: 8
    }
-------------------------
                # Saving last epoch that is within the tolerance of the best loss
                if valid_loss - best_valid_loss < NEAR_LOSS_TOLERANCE:
                    if near_valid_loss_step is not None:
                        search_path = os.path.join(train_dir, 'best', f"{MODEL_SCOPE}_vloss-*.ckpt-{near_valid_loss_step}.*")
                        for f in gfile.Glob(search_path):
                            tf.logging.info(f"Deleting checkpoint file: {f}")
                            gfile.Remove(f)
                    near_valid_loss_step = training_step
                    checkpoint_path = os.path.join(train_dir, 'best', f"{MODEL_SCOPE}_vloss-{valid_loss:.5f}.ckpt")
                    tf.logging.info(f"Saving near loss model to {checkpoint_path}-{training_step}")
                    saver.save(sess, checkpoint_path, global_step=training_step)

-------------------------
def upsample_aft(ds_layers, img_size):
    """
        Takes in a collection of downsampled layers, applies two transposed convolutions for each input layer returns
        the results. A 1x1 convolution is added after the upsample
        
        Returns the upsampled layers for segments and contours as separate arrays
        
        kernel size calculated per here:
        http://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/        

        TODO: bilinear upsampling init? This would require a conv->tconv or tconv->conv where the tconv keeps the channels
        the same and the conv adjusts to the proper channels.
        TODO: regularization? The dcan paper has L2 in the formula. What about dropout? Slim's resnet I believe has L2, need to check
    """
    
    segment_outputs = []
    contour_outputs = []
    
    for i, ds_layer in enumerate(ds_layers):
        factor = img_size // ds_layer.shape.as_list()[1]
        kernel = 2 * factor - factor % 2

        tf.logging.debug(f"layer {i+1} kernel, stride (factor): {kernel, factor}")
        tf.logging.info(f"Layer shape: {ds_layer.shape.as_list()}")

        # Default xavier_initializer is used for the weights here.
        # TODO: this is uniform, should use gaussian per dcan paper?
        net = layers.conv2d_transpose(ds_layer, 
                                      1, 
                                      kernel, 
                                      factor, 
                                      padding='SAME', 
                                      activation_fn=tf.nn.relu,
                                      scope=f"tconv{i+1}_seg")
        net = layers.conv2d(net, 1, 1, activation_fn=None, scope=f"conv{i+1}_seg")

        segment_outputs.append(net)

        net = layers.conv2d_transpose(ds_layer,
                                      1, 
                                      kernel, 
                                      factor,
                                      padding='SAME', 
                                      activation_fn=tf.nn.relu,
                                      scope=f"tconv{i+1}_con")
        net = layers.conv2d(net, 1, 1, activation_fn=None, scope=f"conv{i+1}_con")

        contour_outputs.append(net)
    
    return segment_outputs, contour_outputs

-------------------------
def upsample_old(ds_layers, img_size):
    """
        Takes in a collection of downsampled layers, applies two transposed convolutions for each input layer returns
        the results. A 1x1 convolution is performed before the transposed convolution
        
        Returns the upsampled layers for segments and contours as separate arrays
        
        kernel size calculated per here:
        http://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/        

        TODO: bilinear upsampling init? This would require a conv->tconv or tconv->conv where the tconv keeps the channels
        the same and the conv adjusts to the proper channels.
    """
    
    segment_outputs = []
    contour_outputs = []
    
    for i, ds_layer in enumerate(ds_layers):
        factor = img_size // ds_layer.shape.as_list()[1]
        kernel = 2 * factor - factor % 2

        tf.logging.debug(f"layer {i+1} kernel, stride (factor): {kernel, factor}")
        tf.logging.info(f"Layer shape: {ds_layer.shape.as_list()}")

        # Default xavier_initializer is used for the weights here.
        # TODO: this is uniform, should use gaussian per dcan paper?
        net = layers.conv2d(ds_layer, ds_layer.shape.as_list()[-1], 1, activation_fn=tf.nn.relu, scope=f"conv{i+1}_seg")
        net = layers.conv2d_transpose(net, 
                                      1, 
                                      kernel, 
                                      factor, 
                                      padding='SAME', 
                                      activation_fn=None,
                                      scope=f"tconv{i+1}_seg")

        segment_outputs.append(net)

        net = layers.conv2d(ds_layer, ds_layer.shape.as_list()[-1], 1, activation_fn=tf.nn.relu, scope=f"conv{i+1}_con")
        net = layers.conv2d_transpose(net,
                                      1, 
                                      kernel, 
                                      factor,
                                      padding='SAME', 
                                      activation_fn=None,
                                      scope=f"tconv{i+1}_con")

        contour_outputs.append(net)
    
    return segment_outputs, contour_outputs


def upsample2(seg_layers, con_layers, img_size):
    """
        Takes in a collection of downsampled layers, applies two transposed convolutions for each input layer returns
        the results. A 1x1 convolution is performed before the transposed convolution
        
        Returns the upsampled layers for segments and contours as separate arrays
        
        kernel size calculated per here:
        http://warmspringwinds.github.io/tensorflow/tf-slim/2016/11/22/upsampling-and-image-segmentation-with-tensorflow-and-tf-slim/        

        TODO: bilinear upsampling init? This would require a conv->tconv or tconv->conv where the tconv keeps the channels
        the same and the conv adjusts to the proper channels.
    """
    
    segment_outputs = []
    contour_outputs = []
    
    for i in range(len(seg_layers)):
        # seg and con layers have the same shape so this is fine
        factor = img_size // seg_layers[i].shape.as_list()[1]
        kernel = 2 * factor - factor % 2

        tf.logging.debug(f"layer {i+1} kernel, stride (factor): {kernel, factor}")
        tf.logging.info(f"Layer shape: {seg_layers[i].shape.as_list()}")

        # Default xavier_initializer is used for the weights here.
        # TODO: this is uniform, should use gaussian per dcan paper?
        net = layers.conv2d(seg_layers[i], seg_layers[i].shape.as_list()[-1], 1, activation_fn=tf.nn.relu, scope=f"conv{i+1}_seg")
        net = layers.conv2d_transpose(net, 
                                      1, 
                                      kernel, 
                                      factor, 
                                      padding='SAME', 
                                      activation_fn=None,
                                      scope=f"tconv{i+1}_seg")

        segment_outputs.append(net)

        net = layers.conv2d(con_layers[i], con_layers[i].shape.as_list()[-1], 1, activation_fn=tf.nn.relu, scope=f"conv{i+1}_con")
        net = layers.conv2d_transpose(net,
                                      1, 
                                      kernel, 
                                      factor,
                                      padding='SAME', 
                                      activation_fn=None,
                                      scope=f"tconv{i+1}_con")

        contour_outputs.append(net)
    
    return segment_outputs, contour_outputs

-------------------------
    if learn_color:
        with tf.variable_scope(f"{scope}/learn_color"), slim.arg_scope([layers.conv2d],
                                                                       weights_regularizer=slim.l2_regularizer(l2_weight_decay)):
            input = layers.conv2d(input, 10, 1, padding='VALID', scope=f"conv1")
            input = layers.conv2d(input, 3, 1, padding='VALID', scope=f"conv2")

-------------------------
-------------------------
-------------------------
-------------------------
-------------------------
-------------------------
-------------------------
-------------------------

